{{- if .Values.features.shutdown.enabled -}}
apiVersion: v1
kind: ServiceAccount
metadata:
  name: cluster-cleanup
  namespace: argocd
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: cluster-cleanup
rules:
# ArgoCD Application management
- apiGroups: ["argoproj.io"]
  resources: ["applications"]
  verbs: ["get", "list", "patch", "update"]
# Karpenter NodeClaim management (no longer need nodepool patch)
- apiGroups: ["karpenter.sh"]
  resources: ["nodeclaims"]
  verbs: ["get", "list", "delete", "watch"]
# Node listing for verification
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "list"]
# Pod management for restarting Karpenter
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "delete"]
# Deployment management for restarting Karpenter and scaling down Kyverno
- apiGroups: ["apps"]
  resources: ["deployments", "deployments/scale"]
  verbs: ["get", "list", "patch", "update", "watch"]
# Webhook management for removing Kyverno webhooks
- apiGroups: ["admissionregistration.k8s.io"]
  resources: ["validatingwebhookconfigurations", "mutatingwebhookconfigurations"]
  verbs: ["get", "list", "delete"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: cluster-cleanup
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-cleanup
subjects:
- kind: ServiceAccount
  name: cluster-cleanup
  namespace: argocd
---
apiVersion: batch/v1
kind: Job
metadata:
  name: cluster-cleanup
  namespace: argocd
  annotations:
    argocd.argoproj.io/hook: PostSync
spec:
  ttlSecondsAfterFinished: 3600  # Keep job for 1 hour after completion
  backoffLimit: 3
  template:
    metadata:
      name: cluster-cleanup
    spec:
      serviceAccountName: cluster-cleanup
      restartPolicy: OnFailure
      containers:
      - name: cleanup
        # renovate: datasource=docker depName=alpine/k8s
        image: {{ .Values.features.shutdown.image }}
        command:
        - sh
        - -c
        - |
          set -e
          
          echo "=========================================="
          echo "Starting Cluster Cleanup Process"
          echo "=========================================="
          echo ""
          
          # Step 0: Remove Kyverno (Scale down first to prevent recreation, then remove webhooks)
          echo "Step 0: Removing Kyverno..."

          echo "Scaling down Kyverno deployments..."
          if kubectl -n kyverno get deploy >/dev/null 2>&1; then
             kubectl -n kyverno scale deploy --replicas=0 --all
             echo "✅ Scaled down all kyverno deployments"
          else
             echo "⚠️ Kyverno namespace or deployments not found"
          fi
          echo ""
          
          echo "Deleting all Kyverno webhook configurations..."
          if kubectl delete validatingwebhookconfigurations,mutatingwebhookconfigurations -l webhook.kyverno.io/managed-by=kyverno --ignore-not-found; then
             echo "✅ Removed all kyverno webhooks"
          else
             echo "⚠️ Failed to remove some kyverno webhooks (or none found)"
          fi
          echo ""
          
          # Step 1: Stop Bootstrap ArgoCD App Auto-Sync
          echo "Step 1: Disabling auto-sync for bootstrap application..."
          if kubectl get application bootstrap -n argocd >/dev/null 2>&1; then
            kubectl patch application bootstrap -n argocd --type merge -p '{"spec":{"syncPolicy":{"automated":null}}}'
            echo "✅ Auto-sync disabled for bootstrap application"
          else
            echo "⚠️  Bootstrap application not found, skipping..."
          fi
          echo ""
          
          # Step 2: Restart Karpenter to prevent new node spawning
          echo "Step 2: Restarting Karpenter to prevent new node spawning..."
          if kubectl get deployment karpenter -n karpenter >/dev/null 2>&1; then
            echo "Restarting Karpenter deployment..."
            kubectl rollout restart deployment/karpenter -n karpenter
            
            echo "Waiting for rollout to complete..."
            kubectl rollout status deployment/karpenter -n karpenter --timeout=2m || true
            
            KARPENTER_READY=$(kubectl get pods -n karpenter -l app.kubernetes.io/name=karpenter --no-headers 2>/dev/null | grep -c "Running" || echo "0")
            if [ "${KARPENTER_READY}" -gt 0 ]; then
              echo "✅ Karpenter restarted successfully (${KARPENTER_READY} pod(s) running)"
            else
              echo "⚠️  Karpenter may not have restarted properly"
              kubectl get pods -n karpenter -l app.kubernetes.io/name=karpenter
            fi
          else
            echo "⚠️  Karpenter deployment not found, skipping restart..."
          fi
          echo ""
          
          # Step 3: Remove All NodeClaims
          echo "Step 3: Removing all NodeClaims..."
          
          # Check if any nodeclaims exist
          NODECLAIM_COUNT=$(kubectl get nodeclaims -n karpenter --no-headers 2>/dev/null | wc -l | tr -d ' ')
          
          if [ "${NODECLAIM_COUNT}" -gt 0 ]; then
            echo "Found ${NODECLAIM_COUNT} nodeclaim(s) to delete:"
            kubectl get nodeclaims -n karpenter -o custom-columns=NAME:.metadata.name,NODE:.status.nodeName,AGE:.metadata.creationTimestamp
            echo ""
            
            echo "Deleting all nodeclaims..."
            kubectl delete nodeclaims --all -n karpenter
            
            echo "Waiting for nodeclaims to be fully removed (timeout: 10 minutes)..."
            kubectl wait --for=delete nodeclaims --all -n karpenter --timeout=10m || true
            
            # Verify deletion
            REMAINING=$(kubectl get nodeclaims -n karpenter --no-headers 2>/dev/null | wc -l | tr -d ' ')
            if [ "${REMAINING}" -eq 0 ]; then
              echo "✅ All nodeclaims removed successfully"
            else
              echo "⚠️  ${REMAINING} nodeclaim(s) still remaining"
              kubectl get nodeclaims -n karpenter
            fi
          else
            echo "✅ No nodeclaims found, nothing to delete"
          fi
          echo ""
          
          # Step 4: Verify Cleanup
          echo "=========================================="
          echo "Step 4: Verification"
          echo "=========================================="
          echo ""
          
          echo "Checking for remaining nodeclaims..."
          NODECLAIM_COUNT=$(kubectl get nodeclaims -n karpenter --no-headers 2>/dev/null | wc -l | tr -d ' ')
          if [ "${NODECLAIM_COUNT}" -eq 0 ]; then
            echo "✅ No nodeclaims remaining"
          else
            echo "⚠️  ${NODECLAIM_COUNT} nodeclaim(s) still present:"
            kubectl get nodeclaims -n karpenter
          fi
          echo ""
          
          echo "Checking for Karpenter-managed nodes..."
          KARPENTER_NODES=$(kubectl get nodes -l 'karpenter.sh/nodepool' --no-headers 2>/dev/null | wc -l | tr -d ' ')
          if [ "${KARPENTER_NODES}" -eq 0 ]; then
            echo "✅ No Karpenter-managed nodes remaining"
          else
            echo "⚠️  ${KARPENTER_NODES} Karpenter-managed node(s) still present:"
            kubectl get nodes -l 'karpenter.sh/nodepool'
          fi
          echo ""
          
          echo "Checking NodePool CPU limit..."
          
          # Final Summary
          echo "=========================================="
          echo "Cleanup Process Complete"
          echo "=========================================="
          echo ""
          echo "Summary:"
          echo "  - Auto-sync: Disabled"
          echo "  - NodeClaims: ${NODECLAIM_COUNT} remaining"
          echo "  - Karpenter nodes: ${KARPENTER_NODES} remaining"
          echo ""
          
          if [ "${NODECLAIM_COUNT}" -eq 0 ] && [ "${KARPENTER_NODES}" -eq 0 ]; then
            echo "✅ Cluster is ready for infrastructure destruction"
            exit 0
          else
            echo "⚠️  Some resources still remain. Review the output above."
            exit 1
          fi
      # Run on system nodes with critical addons
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: karpenter.sh/nodepool
                operator: DoesNotExist
              - key: node-type
                operator: In
                values:
                - system
                - control-plane
      tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
{{- end }}
